---
title: Development
---

By conducting a stakeholder interview, the already mentioned requirements for PEER and different roles were defined. From this conversation, different roles were derived. These can be divided into a submitter, an examiner and people who only want to find new sources via PEER and do not want to submit or evaluate any papers. When modelling the acceptance process by the assessor, it was important to divide it into three steps (accepted/corrected/verified). This is because the examiner should first indicate whether he/she is the actual examiner of the work before an assessment process should be started and in the second step indicate that he/she has corrected the work but not yet verified it.

Subsequently, the actual project architecture was designed and the first simple functions of smart contracts were tested with the help of Remix.

Initially, an attempt was made to implement all the functional requirements for PEER using a central contract. The reason for this was that a contract alone would lead to fewer problems with the frontend interface and could reduce problems during deployment. This contract should store the data of the submitter, examiner and information about the thesis, as well as the submission and correction of the work. However, due to memory and gas limitations (more information on gas costs will follow) in Remix, this contract could not be deployed. Therefore, the original contract was split into three functional contracts. These can be found in the documentation in the tab "Blockchain - Smart Contracts".

In case of a change of the thesis, for example by adding content, this process should be mapped in a history. When submitting a thesis, an ipfs hash is generated. This hash is stored in an array. If the content of the thesis changes after a successful submission, the submitter has the possibility to update his thesis and upload a new version of his thesis to PEER. A new ipfs hash will be generated again. This is also stored in the same array with a new storage location number. If the work is updated several times, this process would require a dynamic array and thus require a lot of storage capacity. This would ultimately result in high gas costs. To prevent this, the decision was made to limit the length of the array and only allow 2 hashes. This is also stored in the same array with a new storage location number. If the work is updated several times, this process would require a dynamic array and thus require a lot of storage capacity. This would ultimately result in high gas costs.To prevent this, the decision was made to limit the length of the array and only allow 2 hashes. One is intended for the first version, while the second hash contains the latest update. Nevertheless, this compromise offers full transparency, as the original version is always preserved in memory and can be compared with the updated version. 

